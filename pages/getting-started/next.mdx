import { Callout } from 'nextra/components';

# Next.js Integration

This guide covers how to integrate BrowserAI with Next.js. By following these steps, you can easily leverage powerful AI capabilities directly in your Next.js applications.

## Getting Started

Create a [new Next.js project](https://nextjs.org/docs/getting-started/installation) or open an existing one.

Install the required packages:

```bash npm2yarn
npm install browserai
```

BrowserAI makes it simple to start using AI models in your Next.js applications. You can use our `<GenLLM>` component or the `useGenLLM` hook to integrate AI capabilities seamlessly.

## Basic Example

### Using the `<GenLLM>` Component

Create a new component or page in your Next.js project. Here’s how you can use the `<GenLLM>` component to perform a basic model inference:

```jsx filename="pages/index.jsx"
import { GenLLM } from 'browserai';

export default function Home() {
  return (
    <div>
      <h1>AI-Powered Next.js App</h1>
      <GenLLM
        model="Llama7B"
        input="What is the capital of France?"
        render={({ response }) => <p>Response: {response}</p>}
      />
    </div>
  );
}
```

### Using the `useGenLLM` Hook

For more control over your AI interactions, you can use the `useGenLLM` hook. Here’s an example of how to use it:

```jsx filename="pages/index.jsx"
import { useState } from 'react';
import { useGenLLM } from 'browserai';

export default function Home() {
  const [input, setInput] = useState('');
  const { response, runInference } = useGenLLM({ model: 'Llama7B' });

  const handleSubmit = () => {
    runInference(input);
  };

  return (
    <div>
      <h1>AI-Powered Next.js App</h1>
      <input
        type="text"
        value={input}
        onChange={(e) => setInput(e.target.value)}
      />
      <button onClick={handleSubmit}>Ask AI</button>
      {response && <p>Response: {response}</p>}
    </div>
  );
}
```

## Model Selection

BrowserAI provides smart model selection to optimize performance based on your needs. You can specify the model to use for your inference tasks. Here’s how to specify a model:

```jsx filename="pages/index.jsx"
import { GenLLM } from 'browserai';

export default function Home() {
  return (
    <div>
      <h1>AI-Powered Next.js App</h1>
      <GenLLM
        model="Llama7B"
        input="Explain quantum computing."
        render={({ response }) => <p>Response: {response}</p>}
      />
    </div>
  );
}
```

## Dynamic Model Switching

BrowserAI allows you to switch between different models dynamically based on context and user needs. Here’s an example of how to switch models dynamically:

```jsx filename="pages/index.jsx"
import { useState } from 'react';
import { useGenLLM } from 'browserai';

export default function Home() {
  const [model, setModel] = useState('Llama7B');
  const [input, setInput] = useState('');
  const { response, runInference } = useGenLLM({ model });

  const handleSubmit = () => {
    runInference(input);
  };

  return (
    <div>
      <h1>AI-Powered Next.js App</h1>
      <select onChange={(e) => setModel(e.target.value)} value={model}>
        <option value="Llama7B">Llama7B</option>
        <option value="Llama13B">Llama13B</option>
        <option value="BERT">BERT</option>
      </select>
      <input
        type="text"
        value={input}
        onChange={(e) => setInput(e.target.value)}
      />
      <button onClick={handleSubmit}>Ask AI</button>
      {response && <p>Response: {response}</p>}
    </div>
  );
}
```

<Callout type="info">
  You can import both Server and Client components in your fixtures, which run on the server by default. You can also add the `'use client'` directive to a fixture module (or decorator) if you want use Hooks inside it.
</Callout>

## Further Integration

To learn more about integrating BrowserAI with other tools and frameworks, check out the [Quickstarts section](/quickstarts).

## Community

Join the BrowserAI community on [Discord](https://www.browserai.com/s/d). Whether you need help, want to share your creations, or simply chat about AI and web development, our community is the place to be!

If you find a bug in BrowserAI, please report it using our [Bug Report Form](/bug).

Our [Code of Conduct](https://github.com/BrowserAI/browserai/blob/main/.github/CODE_OF_CONDUCT.md) applies to all BrowserAI community channels.

We look forward to seeing what you create with BrowserAI. Let's push the boundaries of what's possible in the browser together!